# Using the jupyter image with S3

We've added experimental support for an S3 backend via the Jupyter [S3 contents plugin](https://github.com/danielfrg/s3contents). This allows persistance of notebooks to an S3-compatible object store.

To use, pass in [Tensorflow-style S3 configuration variables](https://github.com/tensorflow/tensorflow/blob/64b8af0a0859f1729e66649b5f84da508566d09a/tensorflow/docs_src/deploy/s3.md):

```
S3_ENDPOINT=host:port
S3_USE_HTTPS=0
S3_VERIFY_SSL=0
AWS_SECRET_ACCESS_KEY=XXXXXX
AWS_ACCESS_KEY_ID=XXXXXX
AWS_REGION=us-west-1
S3_NOTEBOOK_URL=s3://bucketname/notebooks/notbookname

docker run -i -t --rm  --env-file <(env | egrep "S3|AWS" --color=never ) -p 8888:8888 repo/image:tag
```

Then connect to the URL in the log output and attempt to create a notebook. The files should appear in your S3 object store.
